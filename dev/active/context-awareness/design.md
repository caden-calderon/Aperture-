# LLM Context Self-Awareness ("Metacognition")

> **Status**: Design concept — implement during Phases 2-3 (Context Engine + Compression)
> **Priority**: HIGH — potentially Aperture's most differentiated feature
> **Created**: 2026-02-06

---

## Core Idea

Give the LLM explicit, structured awareness of its own context window. Instead of flying blind through a blob of tokens, the model knows what it has, what's been compressed, what's been removed, and can actively manage its own memory through the proxy.

**Aperture already sits in the proxy layer** — it can inject a context manifest and intercept memory-management commands before they reach the upstream API. The model thinks it has tools; Aperture is actually managing its memory state.

---

## Context Manifest

A structured block injected into the system prompt (or a dedicated zone) that describes the model's current memory state:

```
[CONTEXT MANIFEST — 47 blocks, 142k/200k tokens, 71% capacity]

PRIMACY (4 blocks, 3.2k tokens, pinned):
  - System prompt (1.8k) [pinned:top]
  - Project architecture overview (800) [pinned:top]
  - Code standards (600) [pinned:top]

MIDDLE (34 blocks, 128k tokens):
  - 12 user messages, 14 assistant responses, 8 tool results
  - 6 blocks compressed (trimmed), 2 blocks compressed (summarized)
  - Topics: auth system, database schema, API endpoints, testing

RECENCY (5 blocks, 8.4k tokens):
  - Current task: "implement feature X"
  - User-selected blocks: #12 (auth flow), #27 (db schema), #31 (API types)

COLD STORAGE (12 blocks, archived):
  - Early conversation: project setup, dependency decisions
  - Recallable via @recall("topic")

BUDGET: 58k tokens remaining — safe to expand ~3 summarized blocks
```

### Manifest Properties
- Auto-generated by Context Engine on each request
- Compact (target: <500 tokens for the manifest itself)
- Updates every turn — model always has fresh awareness
- Includes topic summaries so the model knows WHAT it forgot, not just that it forgot

---

## Memory Commands

Commands the model can emit that Aperture intercepts and executes:

### `@expand(block-id | topic)`
Decompress a block back to its original or higher-detail version.
```
@expand(block-27)           → Restore block #27 from "summarized" to "original"
@expand("auth implementation") → Expand all blocks matching topic
```

### `@recall(topic | query)`
Pull blocks back from cold storage / evicted state.
```
@recall("database migration decisions")  → Search archived blocks, re-inject relevant ones
@recall(block-45)                        → Bring back specific block by ID
```

### `@compress(target, level)`
Proactively free up token budget.
```
@compress("middle", "trimmed")     → Compress all middle zone to trimmed
@compress(block-12, "summarized")  → Compress specific block
@compress("stale", "minimal")      → Compress blocks not referenced in 5+ turns
```

### `@pin(block-id)` / `@unpin(block-id)`
Mark blocks as critical — prevent compression/eviction.
```
@pin(block-31)    → This block is essential, protect it
@unpin(block-12)  → No longer critical, can be compressed if needed
```

### `@focus(block-ids)`
Temporarily boost relevance of specific blocks (like user selection).
```
@focus(block-12, block-27, block-31)  → These are relevant to current task
```

### `@archive(target)`
Proactively move blocks to cold storage.
```
@archive("setup conversation")  → Archive early conversation blocks
@archive(block-1..block-10)     → Archive a range
```

---

## User Selection Integration

When the user selects blocks in the Aperture UI and sends a prompt:
1. Selected blocks get tagged in the manifest as `[user-selected]`
2. They move to a "focus" zone or get relevance boost
3. The model sees: "The user thinks these are relevant to this task"
4. This is a structured attention signal — much better than "hey look at this text I'm pasting"

### UI Flow
1. User selects blocks in context panel (click, shift-click, etc.)
2. User types prompt in their AI tool (Claude Code, etc.)
3. Aperture injects: "User has highlighted the following blocks as relevant: [block summaries]"
4. Model uses them with explicit awareness of why they're there

---

## Memory Lifecycle (Read → Use → Archive)

### The Memory Cycle Problem
When the model reads its memories, it generates new understanding. The old memories might now be redundant. Key insight: **memories should evolve, not just accumulate.**

### Proposed Lifecycle
```
1. INJECT   — Manifest + relevant memories injected into context
2. READ     — Model processes memories, gains understanding
3. ACT      — Model produces output using that understanding
4. REFLECT  — Model can emit memory commands:
               @archive("old auth notes")     — Superseded by new understanding
               @update(block-12, "revised")   — Update a memory with new info
               @create("learned: X pattern")  — Create new memory from synthesis
5. COMPACT  — Aperture executes commands, updates manifest for next turn
```

### Auto-Archival Heuristics
- If model creates a new memory that covers the same topic as an old one → auto-archive old
- If model explicitly references a memory then produces updated understanding → flag old as stale
- Topic clustering can detect overlap between old and new memories
- Staleness score: blocks not referenced in N turns get progressively compressed

### The "Memory Metabolism" Concept
Memories aren't static — they have a lifecycle:
```
FRESH → ACTIVE → REFERENCED → STALE → COMPRESSED → ARCHIVED → EVICTED
```
Each state has different compression levels and retrieval costs. The model (and Aperture) manage this lifecycle together.

---

## Design Challenges & Hurdles

### 1. Token Budget for Manifest
The manifest itself costs tokens. Need to keep it compact but useful.
- **Solution**: Tiered detail — summary manifest always included (~200 tokens), detailed manifest on request (~500 tokens)
- Topic summaries instead of full block previews

### 2. Command Parsing Reliability
The model might emit malformed commands or hallucinate block IDs.
- **Solution**: Fuzzy matching for topics, validate block IDs against manifest, graceful failures with toast notifications to user
- Commands should be simple enough that any model can emit them

### 3. Memory Coherence After Archive
When old memories are archived and new ones created, the new ones need to be self-contained.
- **Solution**: When archiving, verify the new memory that supersedes it contains the critical information
- The Cleaner Sidecar (Phase 7) could validate coherence

### 4. Multi-Turn Context Drift
Over many turns, the manifest needs to stay accurate and not drift from reality.
- **Solution**: Manifest is regenerated from ground truth (actual block state) every turn, never from previous manifest

### 5. User Trust & Transparency
Users need to see and approve what the model is doing to their context.
- **Solution**: All memory commands are visible in the Aperture UI. User can approve/deny/undo. Toast notifications for automated actions.
- "Claude archived 3 blocks and expanded 1" shown in status bar

### 6. Provider Compatibility
Different LLMs have different capabilities. Some may not understand the manifest format.
- **Solution**: Manifest format adapts per provider. Tool-use capable models get @commands as tools. Others get the manifest as structured text in system prompt.

---

## Implementation Phases

### Phase 2 (Context Engine) — Foundation
- Block metadata: topic keywords, reference count, staleness score
- Block state machine: fresh → active → stale → compressed → archived
- Manifest generation from block state

### Phase 3 (Compression) — Memory Management
- @expand / @compress command handling in proxy
- Compression level transitions with original preservation
- Budget-aware auto-compression suggestions in manifest

### Phase 7 (Cleaner Sidecar) — Intelligence
- Auto-generate topic summaries for manifest
- Detect memory overlap / supersession
- Validate coherence when archiving
- Suggest memory lifecycle transitions

### Phase 8 (Search & NLP) — Recall
- @recall command: semantic search over archived blocks
- Topic clustering for manifest summaries
- Natural language memory queries

---

## Open Questions

1. Should the manifest be in the system prompt or a dedicated tool response?
2. How much control should the model have vs. the user vs. Aperture's heuristics?
3. Should memory commands be explicit (@expand) or implicit (model just asks "can you show me the auth discussion")?
4. How do we handle models that try to game the memory system?
5. Should there be a "memory budget" separate from the token budget?
6. Could the model request a "memory diff" — what changed since last turn?

---

## Why This Matters

Every AI tool today treats context as a dumb text buffer. Aperture can make it a **structured, queryable, self-aware memory system**. The model becomes a collaborator in managing its own cognition — not just processing tokens, but understanding what it knows, what it forgot, and what it needs.

This is the feature that turns Aperture from "nice context visualizer" into "essential AI infrastructure."
